{
  "hash": "1c52bb782d3d14b572f7d7fe15cb0eae",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Can I have the CLT, please?A straightforward explanation of the Central Limit Theorem and the magic $n \\geq 30$\ndate: 2024-03-06\ndescription: Shining a light on the Central Limit Theorem and the mythical sample size requirements for the health and social sciences\ncategories:\n - r\n - clt\n - sample size\n - t–test\n - normal distribution\n - statistics\n - Gaussian\n - random variables\ndoi: 10.59350/bje88-8r592\ncitation: true\n#draft: true\n---\n\n\n\n\n## The Central Limit Theorem\n\nThe rudiments of the Central Limit Theorem can be traced back to Bernoulli, who famously penned: “even the stupidest person without any prior instruction knows that the more observations are made, the less danger there is of missing the target”, hinting at the notion that, as the number of trials increases, we're more likely to arrive at an average outcome. The Central limit theorem derives its name from the fact that we're using a parameter of *central* tendency – typically the mean, median, or mode– to arrive at the *limiting distribution* of independent random variables [In this context, independence refers to the probability of one variable not affecting the probability of another variable.]{.aside}– which, under certain conditions, will typically be the standard normal distribution. To put it differently, by sampling a finite population an increasing number of times and using the mean of the $n$ samples as our metric, we will see how our histogram for the population of sampled means will conform to a standard normal curve. By estimating the limiting distribution– think normal distribution– of our independent variables, the theorem helps us answer the question:\n\n> If an outcome $p$ has occurred $p$ times out of $p + q = n$ number of trials, what's the probability of our desired outcome occurring $r$ times in a further $r + q = m$ number of trials?\n\nLet's now talk about the *conditions* we must meet for our distribution to converge or arrive at the standard normal distribution with mean equal to zero and variance equal to 1.\n\n::: column-margin\nI'll start referring to a standard normal distribution with mean equal to zero and variance equal to 1 by using the following notation\n\n$$\\mathcal{N}(0,1)$$\n:::\n\n-   How we use CLT\n\n-   How to know when empirical distribution converges to normal distribution?\n\n    ## what's the deal with $n \\geq 30$?\n\n    -   Jacob Cohen (1991) mentioned that at least 30 observations were needed to use the critical-ratio approach used in t-tables when comparing groups. If the sample size is smaller than 30, then students would be forced to “small” sample statistics.\n\n        > It wasn't until some years later that I discovered (mind you, not invented) power analysis, one of whose fruits was the revelation that for a two-independent-group-mean comparison with n = 30 per group at the sanctified two-tailed .05 level, the probability that a medium-sized effect would be labeled as significant by the most modern methods (a t-test) was only .47. Thus, it was approximately a coin flip whether one would get a significant result, even though, in reality, the effect size was meaningful.\n\n        -   Simply a rule of thumb that allowed students to use critical t–t-tables. These tables could only span 30 lines to fit in one page. Fisher created the\n\n            t-table and only went up to n = 30 (Fisher's *Statistical Methods for Research Workers* (1925))\n\n        -   Sample size at least 30 so that the error variance between t–t-distribution and theoretical normal distribution is .25 or less from df = 30 up to infinity.\n\n        -   When data is severely skewed neither the t–test nor the permutation test have much power (are not robust) to correctly identify a statistically significance difference in means between too highly skewed distributions. Even if your data contained tens of thousands of observations, the t–test may not recognize a statistically significance difference in means. The distribution of the data and the number of observations need to be considered when deciding whether the t–test is meaningful and accurate, sometimes thousands of observations may be needed.\n\n    ## Solution\n\n    -   The number of observations needed for our distribution to approximate the standard normal curve will ultimately depend on our data, the question we're seeking to answer, and the test we plan to use to arrive at our hypothesis.\n    -   Use power analysis to determine the sample size needed to obtain statistically significant results using your desired $\\alpha$, $\\beta$, and effect size measure. This way, you don't have to assume\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}